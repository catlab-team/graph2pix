{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "import torchvision.transforms as TF\n",
    "\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from glob import glob\n",
    "from pytorch_fid.inception import InceptionV3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dims = 2048\n",
    "device = \"cuda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "block_idx = InceptionV3.BLOCK_INDEX_BY_DIM[dims]\n",
    "\n",
    "model = InceptionV3([block_idx]).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImagePathDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data_root, files, transforms=None):\n",
    "        self.data_root = data_root\n",
    "        self.file_names = files\n",
    "        self.transforms = transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_names)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        path = self.file_names[i]\n",
    "        gt_path = os.path.join(self.data_root, \"gts\", path)\n",
    "        img_gt = Image.open(gt_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img_gt = self.transforms(img_gt)\n",
    "            \n",
    "        pred_path = os.path.join(self.data_root, \"generated\", path)\n",
    "        img_pred = Image.open(pred_path).convert('RGB')\n",
    "        if self.transforms is not None:\n",
    "            img_pred = self.transforms(img_pred)\n",
    "        return img_gt, img_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex_name = \"art_newbreeder_allparents_bs8_disc\"\n",
    "data_root = f\"../gen_images/{ex_name}\"\n",
    "file_names = [i.split('/')[-1] for i in glob(f\"../gen_images/{ex_name}/gts/*.jpg\")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImagePathDataset(data_root, file_names, transforms=TF.ToTensor())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = torch.utils.data.DataLoader(dataset,\n",
    "                                             batch_size=8,\n",
    "                                             shuffle=False,\n",
    "                                             drop_last=False,\n",
    "                                             num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# cos_sim=cosine_similarity(A.reshape(1,-1),B.reshape(1,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_cos_sim = 0\n",
    "\n",
    "for (batch_gt, batch_pred) in tqdm(dataloader):\n",
    "    batch_gt = batch_gt.to(device)\n",
    "    batch_pred = batch_pred.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        pred_gt = model(batch_gt)[0]\n",
    "        pred_pred = model(batch_pred)[0]\n",
    "        \n",
    "    # If model output is not scalar, apply global spatial average pooling.\n",
    "    # This happens if you choose a dimensionality not equal 2048.\n",
    "    if pred_gt.size(2) != 1 or pred_gt.size(3) != 1:\n",
    "        pred_gt = adaptive_avg_pool2d(pred_gt, output_size=(1, 1))\n",
    "\n",
    "    pred_gt = pred_gt.squeeze(3).squeeze(2).cpu().numpy()\n",
    "    \n",
    "    \n",
    "    # If model output is not scalar, apply global spatial average pooling.\n",
    "    # This happens if you choose a dimensionality not equal 2048.\n",
    "    if pred_pred.size(2) != 1 or pred_pred.size(3) != 1:\n",
    "        pred_pred = adaptive_avg_pool2d(pred_pred, output_size=(1, 1))\n",
    "\n",
    "    pred_pred = pred_pred.squeeze(3).squeeze(2).cpu().numpy()\n",
    "    \n",
    "    for g,p in zip(pred_gt, pred_pred):\n",
    "        avg_cos_sim += cosine_similarity(g.reshape(1,-1), p.reshape(1, -1))\n",
    "    \n",
    "print(f\"{avg_cos_sim[0][0] / dataset.__len__():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Graph2Pix",
   "language": "python",
   "name": "pix-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
